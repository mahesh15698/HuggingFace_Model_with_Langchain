{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh15698/HuggingFace_Model_with_Langchain/blob/main/HuggingFacePractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fec89bc-2f64-4f07-a489-219ee12b6518",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0fec89bc-2f64-4f07-a489-219ee12b6518"
      },
      "source": [
        "# Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7545b9b0-9ecb-472c-8867-ea3e382b6742",
      "metadata": {
        "id": "7545b9b0-9ecb-472c-8867-ea3e382b6742"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aca6be23-6d50-405e-a1f7-e74d1dd11ced",
      "metadata": {
        "id": "aca6be23-6d50-405e-a1f7-e74d1dd11ced"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "00cfc4e1-bda2-4ece-ab2a-1a0d936b9770",
      "metadata": {
        "id": "00cfc4e1-bda2-4ece-ab2a-1a0d936b9770"
      },
      "outputs": [],
      "source": [
        "!pip install text_generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7c5bd75f-a5e7-414f-8935-dd483ce06955",
      "metadata": {
        "id": "7c5bd75f-a5e7-414f-8935-dd483ce06955"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate\n",
        "!pip install  bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd376a27-a54b-4343-94c4-ffdc88f1fbdd",
      "metadata": {
        "id": "bd376a27-a54b-4343-94c4-ffdc88f1fbdd"
      },
      "source": [
        "# Get Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30f1b9f3-3955-4129-86b1-324c352f82e7",
      "metadata": {
        "id": "30f1b9f3-3955-4129-86b1-324c352f82e7"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7feef0b-bbb2-43d7-a27e-726441321a4b",
      "metadata": {
        "id": "e7feef0b-bbb2-43d7-a27e-726441321a4b"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c74f80c9-3778-46ee-a89a-8e377c5c82e4",
      "metadata": {
        "id": "c74f80c9-3778-46ee-a89a-8e377c5c82e4"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import HuggingFaceTextGenInference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "868b09eb-25de-486c-b228-aa735f2e81bc",
      "metadata": {
        "id": "868b09eb-25de-486c-b228-aa735f2e81bc"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a261b1-a72d-40b2-bab4-344d3e48be0a",
      "metadata": {
        "id": "b0a261b1-a72d-40b2-bab4-344d3e48be0a"
      },
      "source": [
        "# Step 03: Setting the Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "218ba697-d4b4-4078-b83e-f6bac6bc905b",
      "metadata": {
        "id": "218ba697-d4b4-4078-b83e-f6bac6bc905b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"Put you access token from Hugging Face\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90d1b1c5-bc2f-430f-aeb8-ade9a698be40",
      "metadata": {
        "id": "90d1b1c5-bc2f-430f-aeb8-ade9a698be40"
      },
      "source": [
        "### Text2Text Generation Models | Seq2Seq Models | Encoder-Decoder Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42add594-8d12-4542-9b60-f728265e4cd4",
      "metadata": {
        "id": "42add594-8d12-4542-9b60-f728265e4cd4"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b4ce36-6994-4db8-bb62-5f29f4383b2f",
      "metadata": {
        "id": "f3b4ce36-6994-4db8-bb62-5f29f4383b2f"
      },
      "outputs": [],
      "source": [
        "# llm = HuggingFaceHub(repo_id='facebook/mbart-large-50', model_kwargs={'temperature':1.5})\n",
        "# llm = llm=HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={'temperature':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72606a92-d0d9-4af3-a110-4ec4187b1552",
      "metadata": {
        "id": "72606a92-d0d9-4af3-a110-4ec4187b1552"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(llm=HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={'temperature':0}),prompt = prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6fb074-222e-4fec-8cca-e5254653573c",
      "metadata": {
        "id": "9a6fb074-222e-4fec-8cca-e5254653573c",
        "outputId": "9df14fe0-be49-46ab-a468-da8bb51a2615"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'kool kool'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(\"Indian Fastfood\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef74e6b2-45f6-4eed-b578-d4c88f48a35d",
      "metadata": {
        "id": "ef74e6b2-45f6-4eed-b578-d4c88f48a35d"
      },
      "outputs": [],
      "source": [
        "chain2 = LLMChain(llm=HuggingFaceHub(repo_id='facebook/mbart-large-50', model_kwargs={'temperature':0.5}),prompt = prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe60f42-d35c-4688-818e-e9685ee02438",
      "metadata": {
        "id": "efe60f42-d35c-4688-818e-e9685ee02438",
        "outputId": "de4d8a10-26d9-472b-d397-cbf234c80522"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes Indian Fastfood'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain2.run(\"Indian Fastfood\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d872cb4-b869-4644-a5da-f145ac93fa3f",
      "metadata": {
        "id": "3d872cb4-b869-4644-a5da-f145ac93fa3f"
      },
      "source": [
        "# Text Generation Models | Decoder Only Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7c119d-c4da-4c03-bbb2-5d5ed00a5d05",
      "metadata": {
        "id": "cf7c119d-c4da-4c03-bbb2-5d5ed00a5d05"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "373c12b9-7cf8-4888-bd7a-c27dd992f8a9",
      "metadata": {
        "id": "373c12b9-7cf8-4888-bd7a-c27dd992f8a9"
      },
      "outputs": [],
      "source": [
        "model_id='google/flan-t5-large'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d43205-9088-446e-8670-7c967808d82f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5ab97b3afd734af5a154823a8bc62ed8",
            "0a24cc019aa1430fa5850d7c9eeddd36",
            "3031e56bbaf141a2900403c74590c57f",
            "5d68a97cc81c476ebc92e3058332bc49"
          ]
        },
        "id": "f1d43205-9088-446e-8670-7c967808d82f",
        "outputId": "12834441-9539-4abb-f9da-439637727956"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ab97b3afd734af5a154823a8bc62ed8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\anaconda3\\envs\\envlangchain\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--google--flan-t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a24cc019aa1430fa5850d7c9eeddd36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3031e56bbaf141a2900403c74590c57f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d68a97cc81c476ebc92e3058332bc49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8c8362-9ca4-43d4-822f-7dac6f9c25a5",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "09954a18c42c4863b0da49326fa32d0d",
            "97f0d23b4f3c4e42b87efe31148edcbb",
            "26e25c4dfc5345ee8654a56640b184c8"
          ]
        },
        "id": "2c8c8362-9ca4-43d4-822f-7dac6f9c25a5",
        "outputId": "2038221d-ec1b-45cf-d67d-fbd56912b18d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09954a18c42c4863b0da49326fa32d0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97f0d23b4f3c4e42b87efe31148edcbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26e25c4dfc5345ee8654a56640b184c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id,device_map='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97edb215-975d-4335-b5ac-6fb1a8f15438",
      "metadata": {
        "id": "97edb215-975d-4335-b5ac-6fb1a8f15438"
      },
      "outputs": [],
      "source": [
        "pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1ed70e-e1d2-4011-866f-c8a58aac405f",
      "metadata": {
        "id": "ae1ed70e-e1d2-4011-866f-c8a58aac405f"
      },
      "outputs": [],
      "source": [
        "local_llm = HuggingFacePipeline(pipeline=pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65492ee4-4f73-4769-b84e-8d768bc5a634",
      "metadata": {
        "id": "65492ee4-4f73-4769-b84e-8d768bc5a634"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"name\"],\n",
        "    template=\"Can you tell me about footballer {name}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bf2f8e8-3679-42db-b0fc-c65bc98f4115",
      "metadata": {
        "id": "9bf2f8e8-3679-42db-b0fc-c65bc98f4115"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(llm=local_llm,prompt = prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ce6c718-39ef-4138-8a89-323678d05919",
      "metadata": {
        "id": "4ce6c718-39ef-4138-8a89-323678d05919",
        "outputId": "494fa576-b4f5-4fcd-ac60-0a870ecc0a4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sunil Chetri (born 24 August 1971) is a former Indian footballer who played as a forward.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(\"sunil chetri\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3edc3c03-77dc-4aef-8dc3-90edbf674616",
      "metadata": {
        "id": "3edc3c03-77dc-4aef-8dc3-90edbf674616"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}